{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer-Learning\n",
    "\n",
    "Download images and store in resource folder (/res)\n",
    "- https://downloads.codingcoursestv.eu/037%20-%20neuronale%20netze/PetImages.zip\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import vgg16\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "# local imports\n",
    "import plai.workspace.init # source setup.bash\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print sample image of dataset\n",
    "ws_root = plai.workspace.init.get_ws_path()\n",
    "dataset_path = os.path.join(ws_root, \"res\", \"data\", \"PetImages\")\n",
    "os.listdir( os.path.join(dataset_path, \"Cat\") )\n",
    "Image.open( os.path.join(dataset_path, \"Cat\", \"9240.jpg\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "# @todo Use this ImageDataGenerator for large datasets (e.g. above RAM storage)\n",
    "gen = ImageDataGenerator()\n",
    "\n",
    "train_generator = gen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @brief\n",
    "def read_images(path):\n",
    "    files = os.listdir(path)\n",
    "    files = [file for file in files if file[-4:] == \".jpg\"]\n",
    "    \n",
    "    # Prepare images (resize)\n",
    "    # https://pillow.readthedocs.io/en/3.1.x/reference/Image.html\n",
    "    images = []\n",
    "    \n",
    "    for file in tqdm(files):\n",
    "        try:\n",
    "            image = Image.open(os.path.join(path, file))\n",
    "            image = image.resize( (224, 224), Image.LANCZOS)\n",
    "            image = image.convert(\"RGB\")\n",
    "\n",
    "            image = np.asarray(image)\n",
    "            images.append(image)\n",
    "        except OSError:\n",
    "            pass\n",
    "        \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read cat and dog data into RAM\n",
    "cats = read_images( os.path.join(dataset_path, \"Cat\") )\n",
    "dogs = read_images( os.path.join(dataset_path, \"Dog\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to numpy array\n",
    "# @todo use all instead of first 1000 (RAM issues)\n",
    "dogs = np.asarray(dogs)[:1000]\n",
    "cats = np.asarray(cats)[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append cats and dogs\n",
    "x = np.concatenate([dogs, cats])\n",
    "x = x.astype(np.float32)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add labels\n",
    "y_dogs = np.zeros(len(dogs))\n",
    "y_cats = np.ones(len(cats))\n",
    "\n",
    "y = np.concatenate([y_dogs, y_cats])\n",
    "y = y.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale image pixel depth\n",
    "x_scaled = x / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a new CNN from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CNN \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense, MaxPooling2D, Dropout, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation=\"relu\", input_shape=(224, 224, 3)))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation=\"relu\"))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation=\"relu\"))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation=\"relu\"))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(1024, activation=\"relu\"))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapt optimizer\n",
    "# Solver diverges if learning rate to high!\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.00001), loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model from start\n",
    "# This takes forever (even on GPU up to several hours!)\n",
    "model.fit(x_scaled, y, epochs=50, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free RAM\n",
    "del x_scaled\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a pre-trained VGG16 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load VGG16 CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "import keras.applications.vgg16 as vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data (e.g. scale)\n",
    "x_vgg16 = vgg16.preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CNN based on VGG16 without last / top layer (output)\n",
    "vgg16_model = vgg16.VGG16(include_top=False, input_shape=(224, 224, 3))\n",
    "vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not optimize VGG16 weights > Takes a lot of computational time\n",
    "# And these weights are already good to detect objects!\n",
    "vgg16.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add output layers to cropped VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new keras CNN based on VGG16 with new output layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(vgg16_model)\n",
    "\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(4096, activation=\"relu\"))\n",
    "model2.add(Dense(1024, activation=\"relu\"))\n",
    "model2.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "# Caution, this also takes a lot of time, as all images are run through VGG16 during\n",
    "# optimization. See next model to further boost your optimization speed!!!\n",
    "model2.compile(optimizer=Adam(lr=0.00001), loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "model2.fit(x, y, epochs=50, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run all images through VGG16 net and train on this data (30x boost!)\n",
    "And use this data to train newly added output layers at end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all x data throug VGG16 net\n",
    "x_after_vgg = vgg16_model.predict(x, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print shape of processes input data\n",
    "x_after_vgg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_after_vgg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new keras CNN without VGG16 but using its processed images\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model3 = Sequential()\n",
    "# model2.add(vgg16_model)\n",
    "\n",
    "model3.add(Flatten( input_shape=(7, 7, 512)))\n",
    "model3.add(Dense(4096, activation=\"relu\"))\n",
    "model3.add(Dense(1024, activation=\"relu\"))\n",
    "model3.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle data (which is sorted after cats/dogs)\n",
    "# This is necessary as we use validation_split in next step\n",
    "# ... which uses last 20% of data\n",
    "from sklearn.utils import shuffle\n",
    "x_after_vgg, y = shuffle(x_after_vgg, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model using x_after_vgg\n",
    "model3.compile(optimizer=Adam(lr=0.00001), loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "model3.fit(x_after_vgg, y, epochs=50, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model3.save('/tmp/transfer_learning_cats_dogs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
