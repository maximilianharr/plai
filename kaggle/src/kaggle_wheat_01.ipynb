{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Global-Wheat-Detection Dataset <a class=\"anchor\" id=\"top\"></a>\n",
    "\n",
    "https://www.kaggle.com/c/global-wheat-detection\n",
    "\n",
    "## Table of Content\n",
    "* [CNN Models](#cnn_models)\n",
    "* [Image Helpers](#image_helpers)\n",
    "* [Data Helpers](#data_helpers)\n",
    "* [Prepare Data](#prepare_data)\n",
    "* [Visualize Data](#visualize_data)\n",
    "* [Augment Data](#augment_data)\n",
    "* [Generate Model](#generate_model)\n",
    "* [Train Model](#train_model)\n",
    "* [Show Results](#show_results)\n",
    "\n",
    "### Useful Notebooks (kudos!)\n",
    "- Augmentations, Data Cleaning and Bounding Boxes  \n",
    "  https://www.kaggle.com/reighns/augmentations-data-cleaning-and-bounding-boxes\n",
    "- EfficientDet  \n",
    "  https://www.kaggle.com/shonenkov/training-efficientdet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Variables <a class=\"anchor\" id=\"user_variables\"></a> \n",
    "[got to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User Variables\n",
    "data_root = os.path.join(os.environ[\"HOME\"], 'workspace', 'plai', 'res', 'data') # Leave empty for upload on kaggle\n",
    "model_root = os.path.join(os.environ[\"HOME\"], 'workspace', 'plai', 'res', 'trained') \n",
    "\n",
    "RUN_PREPROCESSING = False\n",
    "RUN_VISUALIZATION = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative paths\n",
    "data_path = os.path.join(data_root, 'kaggle', 'input', 'global-wheat-detection')\n",
    "train_image_folder = os.path.join(data_root, 'kaggle', 'input', 'global-wheat-detection', 'train')\n",
    "train_csv = pd.read_csv( os.path.join(data_path, 'train.csv') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Models <a class=\"anchor\" id=\"cnn_models\"></a> \n",
    "[got to top](#top)\n",
    "\n",
    "## Darknet\n",
    "Darknet-19 Architecture [3] | Darknet-53 Architecture [2]\n",
    ":-:|:-:\n",
    "<img src=\"darknet_19.png\" alt=\"Darknet-19 Architecture [3]\" width=\"300\"/>|<img src=\"darknet_53.png\" alt=\"Darknet-53 Architecture [2]\" width=\"300\"/>\n",
    "\n",
    "### Darknet-19\n",
    "Backbone (classification model) of YOLO and YOLO v2. \n",
    "\n",
    "### Darknet-53\n",
    "Backbone (classification model) of YOLO v3  \n",
    "\n",
    "## YOLO\n",
    "\n",
    "### YOLO v1\n",
    "YOLO Overview [4] | YOLO Architecture [1]\n",
    ":-:|:-:\n",
    "<img src=\"yolo_overview.png\" alt=\"YOLO Overview [4]\" width=\"400\"/>|<img src=\"yolo.png\" alt=\"YOLO Architecture [1]\" width=\"400\"/>\n",
    "\n",
    "### YOLO v3\n",
    "\n",
    "[1] \n",
    "@inproceedings{redmon2016you,\n",
    "  title={You only look once: Unified, real-time object detection},\n",
    "  author={Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},\n",
    "  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},\n",
    "  pages={779--788},\n",
    "  year={2016}\n",
    "}\n",
    "\n",
    "[2]\n",
    "@article{redmon2018yolov3,\n",
    "  title={Yolov3: An incremental improvement},\n",
    "  author={Redmon, Joseph and Farhadi, Ali},\n",
    "  journal={arXiv preprint arXiv:1804.02767},\n",
    "  year={2018}\n",
    "}\n",
    "\n",
    "[3]\n",
    "@inproceedings{redmon2017yolo9000,\n",
    "  title={YOLO9000: better, faster, stronger},\n",
    "  author={Redmon, Joseph and Farhadi, Ali},\n",
    "  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},\n",
    "  pages={7263--7271},\n",
    "  year={2017}\n",
    "}\n",
    "\n",
    "[4]\n",
    "https://lilianweng.github.io/lil-log/2018/12/27/object-detection-part-4.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"@package cnn_models\n",
    "\n",
    "  @brief Selection of CNN networks in keras (e.g. Yolo)\n",
    "      Papers:\n",
    "          YOLO: https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Redmon_You_Only_Look_CVPR_2016_paper.pdf\n",
    "          YOLO9000: https://pjreddie.com/media/files/papers/YOLO9000.pdf\n",
    "          YOLOv3: https://arxiv.org/pdf/1804.02767.pdf\n",
    "      \n",
    "  \n",
    "  @author Maximilian Harr <maximilian.harr@gmail.com>\n",
    "  @date 03.06.2020\n",
    "\n",
    "  @bug\n",
    "  @warning\n",
    "  @todo\n",
    " \n",
    "\"\"\"\n",
    "## IMPORTS #######################################################################################\n",
    "\n",
    "## CLASSES #######################################################################################\n",
    "\n",
    "class Yolo():\n",
    "    \"\"\" \n",
    "    CNN that detect objects (classification + bounding box) \n",
    "        https://pjreddie.com/darknet/yolo/\n",
    "    \"\"\"\n",
    "    None\n",
    "## FUNCTIONS #####################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"@package test_cnn_models\n",
    "\n",
    "  @brief Unittest for CNN models\n",
    "  \n",
    "  @author Maximilian Harr <maximilian.harr@gmail.com>\n",
    "  @date 03.06.2020\n",
    "\n",
    "  @bug\n",
    "  @warning\n",
    "  @todo\n",
    " \n",
    "\"\"\"\n",
    "\n",
    "# IMPORTS ########################################################################################\n",
    "import unittest\n",
    "\n",
    "# Local\n",
    "\n",
    "# CLASSES ########################################################################################\n",
    "\n",
    "class TestCnnModels(unittest.TestCase):\n",
    "    \n",
    "    def test_yolo(self):\n",
    "        \n",
    "        self.assertEqual(True, True)\n",
    "    \n",
    "    \n",
    "# FUNCTIONS ######################################################################################\n",
    "\n",
    "\n",
    "# MAIN ###########################################################################################\n",
    "if __name__ == '__main__':\n",
    "    #unittest.main()\n",
    "    unittest.main(argv=[''], verbosity=2, exit=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Helpers <a class=\"anchor\" id=\"image_helpers\"></a> \n",
    "[got to top](#top)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"@package image_helpers\n",
    "\n",
    "  @brief Helper functions to visualize images (e.g. bounding boxes)\n",
    "  \n",
    "  @author Maximilian Harr <maximilian.harr@gmail.com>\n",
    "  @date 01.06.2020\n",
    "\n",
    "  @bug\n",
    "  @warning\n",
    "  @todo\n",
    " \n",
    "\"\"\"\n",
    "## IMPORTS #######################################################################################\n",
    "import cv2\n",
    "import glob\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from skimage import io, exposure\n",
    "from tqdm.notebook import tqdm \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## CLASSES #######################################################################################\n",
    "\n",
    "class ImageHelper():\n",
    "    \"\"\" Class for visualization / checking images. \"\"\"\n",
    "    \n",
    "    def check_all_image_sizes(self, image_folder_path: str, width: int, height: int) -> bool:\n",
    "        \"\"\"\n",
    "        check_all_image_sizes Check if all images in folder have a certain size\n",
    "            @param image_folder_path: path to folder\n",
    "            @param width, height: image dimension\n",
    "            @return: boolean\n",
    "        \"\"\"\n",
    "        \n",
    "        # Check input parameters\n",
    "        if not type(image_folder_path) == str or not type(width) == int or not type(height) == int:\n",
    "            raise TypeError('Wrong datatype provided')\n",
    "        if not os.path.isdir(image_folder_path):\n",
    "            raise ValueError('Directory does not exist')\n",
    "        \n",
    "        # Check size of all images\n",
    "        total_img_list = glob.glob(os.path.join(image_folder_path,\"*\"))\n",
    "        counter = 0\n",
    "        \n",
    "        for image in tqdm(total_img_list, desc=\"Checking images\"):\n",
    "            try:\n",
    "                img = cv2.imread(image)\n",
    "                img_height, img_width = img.shape[1], img.shape[0]\n",
    "            except AttributeError:\n",
    "                if not (img_width == width and img_height == height):\n",
    "                    counter = counter + 1\n",
    "        return counter == 0\n",
    "    \n",
    "    def check_bbox(self, bbox: pd.DataFrame) -> bool:\n",
    "        \"\"\"\n",
    "        check_bbox Checks if the boundingbox pandas frame bbox has all necessary columns\n",
    "            @param bbox pandas datafram\n",
    "            @return boolen\n",
    "        \"\"\"\n",
    "        \n",
    "        # Check input parameters\n",
    "        if not type(bbox) == pd.DataFrame:\n",
    "            raise TypeError('Wrong datatype provided')\n",
    "        \n",
    "        # Check if columns exist\n",
    "        if set(['image_name', 'width', 'height', 'x_min', 'x_max', 'y_min', 'y_max', 'class']).issubset(bbox.columns):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def check_image_and_bbox(self, image_folder_path: str, image_bbox_dataframe: pd.DataFrame) -> bool:\n",
    "        \"\"\" \n",
    "        check_image_and_bbox Check image and bbox for consistency\n",
    "            @param image_folder_path path to images\n",
    "            @param image_bbox_dataframe pandas dataframe with images\n",
    "            @return boolean\n",
    "        \"\"\"\n",
    "    \n",
    "        # Check input parameters\n",
    "        if not type(image_folder_path) == str or not type(image_bbox_dataframe) == pd.DataFrame:\n",
    "            raise TypeError('Wrong datatype provided')\n",
    "        if not os.path.isdir(image_folder_path):\n",
    "            raise ValueError('Directory does not exist')\n",
    "        if not self.check_bbox(image_bbox_dataframe):\n",
    "            raise ValueError('Dataframe is not a valid bbox dataframe')\n",
    "\n",
    "        # Check if all images in image_bbox_dataframe are existent\n",
    "        missing_images = []\n",
    "        for image_name in image_bbox_dataframe['image_name'].unique():\n",
    "            image_path = os.path.join(image_folder_path, image_name)\n",
    "            if not os.path.isfile(image_path):\n",
    "                missing_images.append(image_name)\n",
    "        \n",
    "        if len(missing_images) is not 0:\n",
    "            warnings.warn(\"Images specified in Bbox are missing\", UserWarning)\n",
    "            print(missing_images)\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def plot_multiple_img(self, img_matrix_list: list, \n",
    "                          title_list: np.ndarray, \n",
    "                          ncols: int, \n",
    "                          main_title: str = \"\"):\n",
    "        \"\"\"\n",
    "        plot_multiple_img Plots multiple images\n",
    "            @param img_matrix_list list of images (cv2.imread)\n",
    "            @param title_list \n",
    "            @param ncols number of plot columns\n",
    "            @param main_title Title of plot\n",
    "            @return\n",
    "        \"\"\"\n",
    "        \n",
    "        # Check input parameters\n",
    "        if not type(img_matrix_list) == list \\\n",
    "            or not type(title_list) == np.ndarray \\\n",
    "            or not type(ncols) == int \\\n",
    "            or not type(main_title) == str:\n",
    "            raise TypeError('Wrong datatype provided')\n",
    "        \n",
    "        \n",
    "        fig, myaxes = plt.subplots(figsize=(20, 10), nrows=math.ceil(len(img_matrix_list)/ncols), \n",
    "                                   ncols=ncols, squeeze=False)\n",
    "        fig.suptitle(main_title, fontsize = 30)\n",
    "        fig.subplots_adjust(wspace=0.3)\n",
    "        fig.subplots_adjust(hspace=0.3)\n",
    "        for i, (img, title) in enumerate(zip(img_matrix_list, title_list)):\n",
    "            myaxes[i // ncols][i % ncols].imshow(img)\n",
    "            myaxes[i // ncols][i % ncols].set_title(title, fontsize=15)\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_random_images(self, image_folder_path: str, \n",
    "                           ncols: int = 2,\n",
    "                           nimgs: int = 12) -> None:\n",
    "        \"\"\"\n",
    "        plot_random_images Plots random images\n",
    "            @param image_folder_path\n",
    "            @param ncols number of coulums\n",
    "            @param nimgs number of image\n",
    "            @return\n",
    "        \"\"\"\n",
    "        \n",
    "        # Check input parameters\n",
    "        if not type(image_folder_path) == str \\\n",
    "            or not type(ncols) == int \\\n",
    "            or not type(nimgs) == int:\n",
    "            raise TypeError('Wrong datatype provided')\n",
    "        if not os.path.isdir(image_folder_path):\n",
    "            raise ValueError('Directory does not exist')\n",
    "        \n",
    "        # randomly choose 12 images to plot\n",
    "        file_list = os.listdir(image_folder_path)\n",
    "        \n",
    "        img_files_list = np.random.choice(file_list, nimgs)\n",
    "        print(\"The images' names are {}\".format(img_files_list))\n",
    "        img_matrix_list = []\n",
    "\n",
    "        for img_file in img_files_list:\n",
    "            image_file_path = os.path.join(image_folder_path, img_file)\n",
    "            img = cv2.imread(image_file_path)[:,:,::-1]  \n",
    "            img_matrix_list.append(img)\n",
    "\n",
    "        return self.plot_multiple_img(img_matrix_list, title_list = img_files_list, ncols = ncols, main_title=\"Wheat Images\")\n",
    "\n",
    "    def plot_random_images_bbox(self, image_folder_path: str, \n",
    "                                image_bbox_dataframe: pd.DataFrame, \n",
    "                                ncols: int = 2,\n",
    "                                nimgs: int = 12) -> None:\n",
    "        \"\"\"\n",
    "        plot_random_images_bbox Plots random images with bounding boxes\n",
    "            @param image_folder_path\n",
    "            @param image_bbox_dataframe\n",
    "            @param ncols number of coulums\n",
    "            @param nimgs number of image\n",
    "            @return\n",
    "        \"\"\"\n",
    "        \n",
    "        # Check input parameters\n",
    "        if not type(image_folder_path) == str \\\n",
    "            or not type(image_bbox_dataframe) == pd.DataFrame \\\n",
    "            or not type(ncols) == int \\\n",
    "            or not type(nimgs) == int:\n",
    "            raise TypeError('Wrong datatype provided')\n",
    "        if not os.path.isdir(image_folder_path):\n",
    "            raise ValueError('Directory does not exist')\n",
    "        if not self.check_bbox(image_bbox_dataframe):\n",
    "            raise ValueError('Dataframe is not a valid bbox dataframe')\n",
    "            \n",
    "        # randomly choose 12 image.\n",
    "        img_files_list = np.random.choice(list(image_bbox_dataframe['image_name']), nimgs)\n",
    "        print(\"The images' names are {}\".format(img_files_list))\n",
    "        image_file_path_list = []\n",
    "\n",
    "        bbox_list = []\n",
    "        img_matrix_list = []\n",
    "        random_image_matrix_list = []\n",
    "        \n",
    "        # Save images and bounding boxes in new list\n",
    "        for img_file in img_files_list:\n",
    "            \n",
    "            bbox_list.append( image_bbox_dataframe[image_bbox_dataframe['image_name'] == img_file] )\n",
    "            \n",
    "            image_file_path = os.path.join(image_folder_path, img_file)\n",
    "            img = cv2.imread(image_file_path)[:,:,::-1]  \n",
    "            img_matrix_list.append(img)\n",
    "        \n",
    "        # Plot all bounding boxes in image\n",
    "        final_bbox_list = []\n",
    "        for bboxes, img in zip(bbox_list, img_matrix_list):\n",
    "            \n",
    "            box = bboxes[['x_min','x_max', 'y_min', 'y_max']]\n",
    "            random_image = img.copy()\n",
    "            \n",
    "            for bbox in bboxes[['x_min','y_min', 'x_max', 'y_max']].values.astype(int).reshape(-1, 4):\n",
    "                start_point = tuple(np.array(bbox[0:2]))\n",
    "                end_point = tuple(np.array(bbox[2:4]))\n",
    "                color = (255, 0, 0)\n",
    "                thickness = 2\n",
    "                random_image = cv2.rectangle(random_image, start_point, end_point, color, thickness)\n",
    "            \n",
    "            random_image_matrix_list.append(random_image)\n",
    "            \n",
    "        self.plot_multiple_img(random_image_matrix_list, \n",
    "                               title_list = img_files_list, \n",
    "                               ncols=ncols, \n",
    "                               main_title=\"Bounding Box Wheat Images\")   \n",
    "    \n",
    "## FUNCTIONS #####################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"@package test_image_helpers\n",
    "\n",
    "  @brief Unittest for image helpers\n",
    "  \n",
    "  @author Maximilian Harr <maximilian.harr@gmail.com>\n",
    "  @date 01.06.2020\n",
    "\n",
    "  @bug\n",
    "  @warning\n",
    "  @todo\n",
    " \n",
    "\"\"\"\n",
    "\n",
    "# IMPORTS ########################################################################################\n",
    "import unittest\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# Local\n",
    "import plai.workspace.init\n",
    "\n",
    "# CLASSES ########################################################################################\n",
    "\n",
    "class TestImageHelpers(unittest.TestCase):\n",
    "    \n",
    "    def test_check_all_image_sizes(self):\n",
    "        \n",
    "        image_helper = ImageHelper()\n",
    "        \n",
    "        plai_image_folder = os.path.join( plai.workspace.init.get_ws_path(), 'common', 'plai', 'test', 'res', 'imgs')\n",
    "        \n",
    "        self.assertEqual(True, image_helper.check_all_image_sizes(plai_image_folder, width=1024, height=1024) )\n",
    "    \n",
    "    def test_check_bbox(self):\n",
    "        \n",
    "        image_helper = ImageHelper()\n",
    "        \n",
    "        image_bbox = pd.DataFrame(\n",
    "            [['*.jpg', 0, 0, 0, 0, 0, 0, 0],\n",
    "            ['*.jpg', 0, 0, 0, 0, 0, 0, 0]],\n",
    "            columns=['image_name', 'width', 'height', 'x_min', 'x_max', 'y_min', 'y_max', 'class'])\n",
    "                \n",
    "        self.assertEqual(True, image_helper.check_bbox(image_bbox))\n",
    "        \n",
    "    def test_check_image_and_bbox(self):\n",
    "        \n",
    "        image_helper = ImageHelper()\n",
    "    \n",
    "        plai_image_folder = os.path.join( plai.workspace.init.get_ws_path(), 'common', 'plai', 'test', 'res', 'imgs')\n",
    "        image_bbox = pd.DataFrame(\n",
    "            [['b53afdf5c.jpg', 1024, 1024, 0, 0, 0, 0, 0],\n",
    "            ['b6ab77fd7.jpg', 1024, 1024, 0, 0, 0, 0, 0]],\n",
    "            columns=['image_name', 'width', 'height', 'x_min', 'x_max', 'y_min', 'y_max', 'class'])\n",
    "        \n",
    "        self.assertEqual( True, image_helper.check_image_and_bbox(plai_image_folder, image_bbox))\n",
    "        \n",
    "        image_bbox = pd.DataFrame(\n",
    "            [['missing_image.jpg', 1024, 1024, 0, 0, 0, 0, 0]],\n",
    "            columns=['image_name', 'width', 'height', 'x_min', 'x_max', 'y_min', 'y_max', 'class'])\n",
    "        \n",
    "        self.assertEqual( False, image_helper.check_image_and_bbox(plai_image_folder, image_bbox))\n",
    "    \n",
    "    def test_plot_random_images(self):\n",
    "        \n",
    "        image_helper = ImageHelper()\n",
    "\n",
    "        plai_image_folder = os.path.join( plai.workspace.init.get_ws_path(), 'common', 'plai', 'test', 'res', 'imgs')\n",
    "\n",
    "        image_helper.plot_random_images(plai_image_folder, nimgs=6, ncols=3)\n",
    "    \n",
    "    def test_plot_random_images_bbox(self):\n",
    "\n",
    "        image_helper = ImageHelper()\n",
    "\n",
    "        plai_image_folder = os.path.join( plai.workspace.init.get_ws_path(), 'common', 'plai', 'test', 'res', 'imgs')\n",
    "\n",
    "        # Read Bbox annotation file\n",
    "        image_bbox = pd.DataFrame([])\n",
    "        image_bbox_csv = os.path.join( plai.workspace.init.get_ws_path(), 'common', 'plai', 'test', 'res', 'train.csv')\n",
    "\n",
    "        with open(image_bbox_csv, \"r\") as file:\n",
    "            image_bbox = pd.read_csv(image_bbox_csv)\n",
    "\n",
    "        image_helper.plot_random_images_bbox(plai_image_folder, image_bbox, nimgs=6, ncols=3)\n",
    "    \n",
    "# FUNCTIONS ######################################################################################\n",
    "\n",
    "\n",
    "# MAIN ###########################################################################################\n",
    "if __name__ == '__main__':\n",
    "    #unittest.main()\n",
    "    unittest.main(argv=[''], verbosity=2, exit=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Helpers <a class=\"anchor\" id=\"data_helpers\"></a>\n",
    "[got to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"@package data_helpers\n",
    "\n",
    "  @brief Helper functions to convert text data (e.g. csv etc)\n",
    "  \n",
    "  @author Maximilian Harr <maximilian.harr@gmail.com>\n",
    "  @date 29.05.2020\n",
    "\n",
    "  @bug\n",
    "  @warning\n",
    "  @todo\n",
    " \n",
    "\"\"\"\n",
    "\n",
    "## IMPORTS #######################################################################################\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "from skimage import io, exposure\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## CLASSES #######################################################################################\n",
    "\n",
    "class BboxHelper():\n",
    "    \"\"\" Class for Bounding box data processing. \"\"\"\n",
    "    None\n",
    "\n",
    "class FileHelper():\n",
    "    \"\"\" Class for checking folders and files. \"\"\"\n",
    "    def folder_filetypes_equal(self, path: str, ignore_folder_type: bool) -> bool :\n",
    "        \"\"\"\n",
    "        folder_file_types_equal Check if all file types in folder are equal\n",
    "            @param path: path to folder\n",
    "            @param ignore_folder_type: Ignore folder file type\n",
    "            @return: boolean\n",
    "        \"\"\"\n",
    "\n",
    "        # Check input parameter\n",
    "        if not type(path) == str and not type(ignore_folder_type) == bool:\n",
    "            raise TypeError('Wrong datatype provided')\n",
    "        if not os.path.isdir(path):\n",
    "            raise ValueError('Directory does not exist')\n",
    "\n",
    "        # Check if all file types are equal\n",
    "        extension_type = []\n",
    "        file_list = os.listdir(path)\n",
    "\n",
    "        for file in file_list:\n",
    "            # Skip folders\n",
    "            if os.path.isdir(os.path.join(path, file)) and ignore_folder_type is True:\n",
    "                continue\n",
    "            extension_type.append(file.rsplit(\".\", 1)[1].lower())\n",
    "\n",
    "        # print(Counter(extension_type).keys())\n",
    "        # print(Counter(extension_type).values())\n",
    "\n",
    "        return len(Counter(extension_type).keys()) == 1\n",
    "\n",
    "\n",
    "## FUNCTIONS #####################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"@package test_data_helpers\n",
    "\n",
    "  @brief Unittest for data helpers\n",
    "  \n",
    "  @author Maximilian Harr <maximilian.harr@gmail.com>\n",
    "  @date 29.05.2020\n",
    "\n",
    "  @bug\n",
    "  @warning\n",
    "  @todo\n",
    " \n",
    "\"\"\"\n",
    "\n",
    "# IMPORTS ########################################################################################\n",
    "import unittest\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Local\n",
    "import plai.workspace.init\n",
    "\n",
    "# CLASSES ########################################################################################\n",
    "\n",
    "class TestDataHelpers(unittest.TestCase):\n",
    "\n",
    "    def test_folder_file_types_equal(self):\n",
    "        plai_dir = os.path.join( plai.workspace.init.get_ws_path(), 'common', 'plai')\n",
    "        plai_img_dir = os.path.join( plai.workspace.init.get_ws_path(), 'common', 'plai', 'test', 'res', 'imgs')\n",
    "        \n",
    "        file_helper = FileHelper()\n",
    "        self.assertEqual( False, file_helper.folder_filetypes_equal(plai_dir, ignore_folder_type=True) )\n",
    "        self.assertEqual( True, file_helper.folder_filetypes_equal(plai_img_dir, ignore_folder_type=True) )\n",
    "        None\n",
    "\n",
    "# FUNCTIONS ######################################################################################\n",
    "\n",
    "\n",
    "# MAIN ###########################################################################################\n",
    "if __name__ == '__main__':\n",
    "    #unittest.main()\n",
    "    unittest.main(argv=[''], verbosity=2, exit=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data <a class=\"anchor\" id=\"prepare_data\"></a>\n",
    "[got to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "train_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get bboxes\n",
    "from pandas import read_csv\n",
    "\n",
    "train_bbox = pd.DataFrame()\n",
    "\n",
    "if RUN_PREPROCESSING:\n",
    "    train_bbox = train_csv # Merely used to initialize space\n",
    "    train_bbox[\"image_name\"] = train_csv[\"image_id\"].apply(lambda x: str(x) + \".jpg\")\n",
    "\n",
    "    # Add columns [x_min, y_min, width, height]\n",
    "    bboxes = np.stack(train_bbox['bbox'].apply(lambda x: np.fromstring(x[1:-1], sep=',')))\n",
    "    for i, column in enumerate(['x_min', 'y_min', 'width', 'height']):\n",
    "        train_bbox[column] = bboxes[:,i]\n",
    "\n",
    "    # Add colums [x_max, y_max]\n",
    "    train_bbox[\"x_max\"] = train_bbox.apply(lambda col: col.x_min + col.width, axis=1)\n",
    "    train_bbox[\"y_max\"] = train_bbox.apply(lambda col: col.y_min + col.height, axis = 1)\n",
    "    train_bbox[\"x_center\"] = train_bbox.apply(lambda col: col.x_min + col.width/2, axis=1)\n",
    "    train_bbox[\"y_center\"] = train_bbox.apply(lambda col: col.y_min + col.height/2, axis = 1)\n",
    "    train_bbox.drop(columns=['bbox'], inplace=True)\n",
    "\n",
    "    # Remove columns\n",
    "    del train_bbox['source']\n",
    "    del train_bbox['image_id']\n",
    "    \n",
    "    # Add class label\n",
    "    train_bbox[\"class\"] = '1'\n",
    "\n",
    "    # Store as *.csv\n",
    "    train_bbox.to_csv( os.path.join(data_path, \"train_bbox.csv\") )\n",
    "    train_bbox.head()\n",
    "else:\n",
    "    train_bbox = pd.read_csv( os.path.join(data_path, \"train_bbox.csv\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity checks\n",
    "file_helper = FileHelper()\n",
    "image_helper = ImageHelper()\n",
    "\n",
    "if RUN_PREPROCESSING:\n",
    "    # \n",
    "    if (len(train_csv[train_csv[\"x_max\"] > 1024]) or \\\n",
    "        len(train_csv[train_csv[\"y_max\"] > 1024]) or \\\n",
    "        len(train_csv[train_csv[\"x_min\"] < 0]) or\n",
    "        len(train_csv[train_csv[\"y_min\"] < 0]) ):\n",
    "        warnings.warn(\"Image normalization required\", UserWarning)\n",
    "\n",
    "    #if image_helper.check_all_image_sizes(train_image_folder, width=1024, height=1024) == False:\n",
    "    #    warnings.warn(\"Actual image size not equal\", UserWarning)\n",
    "\n",
    "    if (len(train_csv[train_bbox[\"x_min\"] < 0]) or \\\n",
    "        len(train_csv[train_bbox[\"y_min\"] < 0]) or \\\n",
    "        len(train_csv[train_bbox[\"x_max\"] > 1024]) or\n",
    "        len(train_csv[train_bbox[\"y_max\"] > 1024]) ):\n",
    "        warnings.warn(\"Bounding box exceeds image\", UserWarning)\n",
    "\n",
    "    if file_helper.folder_filetypes_equal(data_path, ignore_folder_type=True) == False:\n",
    "        warnings.warn(\"File types in folder differ\", UserWarning)\n",
    "\n",
    "    if not image_helper.check_bbox(train_bbox):\n",
    "        warnings.warn(\"Error in bounding boxes\", UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Data <a class=\"anchor\" id=\"visualize_data\"></a>\n",
    "[got to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot random wheat images with bounding boxes\n",
    "image_helper = ImageHelper()\n",
    "if RUN_VISUALIZATION:\n",
    "    image_helper.plot_random_images_bbox(train_image_folder, train_bbox, nimgs=6, ncols=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot wheat heads of certain image\n",
    "def plot_heads_of_image(image_name: str, image_folder, train_bbox: pd.DataFrame()) -> None:\n",
    "    \n",
    "    train_bbox_sample = train_bbox[train_bbox['image_name'] == image_name ]\n",
    "    image_path_full = os.path.join(image_folder, image_name)\n",
    "    image_sample = cv2.imread(  image_path_full)[:,:,::-1]\n",
    "\n",
    "    img_matrix_list = []\n",
    "    img_files_list = []\n",
    "\n",
    "    # Plot wheat heads\n",
    "    for index, bbox in train_bbox_sample.iterrows():\n",
    "        # Crop wheat head\n",
    "        img = cv2.imread( image_path_full )[:,:,::-1]\n",
    "        img = img[ int(bbox.y_min) : int(bbox.y_max) , int(bbox.x_min) : int(bbox.x_max) ,::]\n",
    "        img_matrix_list.append(img)\n",
    "        img_files_list.append(\"head_\" + str(index))\n",
    "\n",
    "    image_helper.plot_multiple_img(img_matrix_list, title_list = np.asarray(img_files_list, dtype=str),\n",
    "                                   ncols = 10, main_title=\"Wheat Heads\")\n",
    "\n",
    "#plot_heads_of_image('b53afdf5c.jpg', train_image_folder, train_bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all wheatheads as separate jpg images\n",
    "train_image_folder_heads = os.path.join(data_root, 'kaggle', 'input', 'global-wheat-detection', 'train_heads')\n",
    "\n",
    "if RUN_PREPROCESSING:\n",
    "    # Create folder for head images    \n",
    "    if not os.path.exists(train_image_folder_heads):\n",
    "        os.makedirs(train_image_folder_heads)\n",
    "\n",
    "    # Plot wheat heads\n",
    "    for index, bbox in tqdm(train_bbox.iterrows(), total=len(train_bbox), unit=\"images\"):\n",
    "        # Crop wheat head\n",
    "        img = cv2.imread( os.path.join(train_image_folder, bbox.image_name) )[:,:,::-1]\n",
    "        img = img[ int(bbox.y_min) : int(bbox.y_max) , int(bbox.x_min) : int(bbox.x_max) ,::]\n",
    "\n",
    "        img_destination = os.path.join(train_image_folder_heads, str(index) + \".jpg\")\n",
    "        cv2.imwrite(img_destination, img)\n",
    "\n",
    "    image_helper.plot_random_images(train_image_folder_heads, nimgs=20, ncols=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which images contain wheatheads\n",
    "file_list = os.listdir(train_image_folder)\n",
    "\n",
    "A = pd.DataFrame(train_bbox['image_name'].unique(), columns={\"image_name\"})\n",
    "B = pd.DataFrame(file_list, columns={\"image_name\"})\n",
    "\n",
    "A_B_union = pd.merge(A, B, how='inner', on=['image_name', 'image_name'] ) # needless, but nice example (docu)\n",
    "A_not_in_B = pd.concat([A, B]).drop_duplicates(keep=False)\n",
    "\n",
    "print(\"Total number of images: %d\" %len(B))\n",
    "print(\"Number of images with bbox: %d\" %len(A_B_union))\n",
    "print(\"Number of images without bbxox: %d\" % len(A_not_in_B))\n",
    "\n",
    "A_not_in_B.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model that detects if wheat is in image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @brief\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm \n",
    "\n",
    "def read_images(path: str, image_names: pd.DataFrame, height, width) -> np.array:\n",
    "    \n",
    "    # Prepare images (resize)\n",
    "    # https://pillow.readthedocs.io/en/3.1.x/reference/Image.html\n",
    "    images = []\n",
    "    \n",
    "    for index, image_name in tqdm(image_names.iterrows(), total=len(image_names), unit=\"images\"):\n",
    "        try:\n",
    "            \n",
    "            image = Image.open(os.path.join(path, image_name.image_name))\n",
    "            image = image.resize( (width, height), Image.LANCZOS)\n",
    "            image = image.convert(\"RGB\")\n",
    "\n",
    "            image = np.asarray(image)\n",
    "            images.append(image)\n",
    "        except OSError:\n",
    "            pass\n",
    "    \n",
    "    # Convert to float\n",
    "    images = np.array(images)\n",
    "    images = images.astype(np.float32)\n",
    "    \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/53698035/failed-to-get-convolution-algorithm-this-is-probably-because-cudnn-failed-to-in\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "# tf.compat.v1.disable_v2_behavior()\n",
    "def tf_configure_gpu( gpu_fraction=0.3: float) -> None:\n",
    "    if tf.__version__[0] == \"2\":\n",
    "        print(\"Tensorflow V2\")\n",
    "\n",
    "        config = tf.compat.v1.ConfigProto()\n",
    "        config.gpu_options.per_process_gpu_memory_fraction = gpu_fraction\n",
    "        config.gpu_options.allow_growth = True\n",
    "        session = tf.compat.v1.Session(config=config)\n",
    "        tf.compat.v1.keras.backend.set_session(session)\n",
    "\n",
    "    else:\n",
    "        print(\"Tensorflow V1\")\n",
    "        \n",
    "        config = tf.ConfigProto()\n",
    "        config.gpu_options.per_process_gpu_memory_fraction = gpu_fraction\n",
    "        config.gpu_options.allow_growth = True\n",
    "        session = tf.Session(config=config)\n",
    "        keras.backend.tensorflow_backend.set_session( session )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup GPU\n",
    "USE_GPU = True\n",
    "\n",
    "if USE_GPU:\n",
    "    tf_configure_gpu( gpu_fraction=0.4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read nowheat and wheat data into RAM\n",
    "TRAIN_HAS_WHEAT_MODEL = True\n",
    "\n",
    "if TRAIN_HAS_WHEAT_MODEL:\n",
    "    nowheat_image_names = pd.DataFrame(A_not_in_B)\n",
    "    wheat_image_names = A_B_union\n",
    "\n",
    "    nowheat_images = read_images( train_image_folder, nowheat_image_names, height=224, width=224 )\n",
    "    wheat_images = read_images( train_image_folder, wheat_image_names, height=224, width=224 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append nowheat and wheat imagess\n",
    "if TRAIN_HAS_WHEAT_MODEL:\n",
    "    x = np.concatenate([nowheat_images, wheat_images])\n",
    "    x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add labels\n",
    "if TRAIN_HAS_WHEAT_MODEL:\n",
    "    y_nowheat = np.zeros(len(nowheat_images))\n",
    "    y_wheat = np.ones(len(wheat_images))\n",
    "\n",
    "    y = np.concatenate([y_nowheat, y_wheat])\n",
    "    y = y.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CNN based on VGG16 without last / top layer (output)\n",
    "# For details: vgg16_model.summary()\n",
    "import tensorflow as tf\n",
    "import keras.applications.vgg16 as vgg16\n",
    "\n",
    "#with tf.device('cpu:0'):\n",
    "vgg16_model = vgg16.VGG16(include_top=False, input_shape=(224, 224, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all x data through VGG16 net now (to save time during training)\n",
    "# Force CPU\n",
    "import tensorflow as tf\n",
    "\n",
    "# Use Transfer Learning on pre-trained VGG16 model\n",
    "\n",
    "if TRAIN_HAS_WHEAT_MODEL:\n",
    "    #with tf.device('cpu:0'):\n",
    "    x_vgg16 = vgg16.preprocess_input(x)\n",
    "    x_after_vgg = vgg16_model.predict(x_vgg16, verbose=True, batch_size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new keras CNN without VGG16 but using its processed images\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "if TRAIN_HAS_WHEAT_MODEL:\n",
    "    model_has_wheat = Sequential()\n",
    "    # model2.add(vgg16_model)\n",
    "\n",
    "    model_has_wheat.add(Flatten( input_shape=(7, 7, 512)))\n",
    "    model_has_wheat.add(Dense(4096, activation=\"relu\"))\n",
    "    model_has_wheat.add(Dense(1024, activation=\"relu\"))\n",
    "    model_has_wheat.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    model_has_wheat.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle data (which is sorted after cats/dogs)\n",
    "# This is necessary as we use validation_split in next step\n",
    "# ... which uses last 20% of data\n",
    "from sklearn.utils import shuffle\n",
    "    \n",
    "if TRAIN_HAS_WHEAT_MODEL:\n",
    "    x_after_vgg, y = shuffle(x_after_vgg, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model using x_after_vgg\n",
    "if TRAIN_HAS_WHEAT_MODEL:\n",
    "    #with tf.device('cpu:0'):\n",
    "    model_has_wheat.compile(optimizer=Adam(lr=0.0001), loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "    model_has_wheat.fit(x_after_vgg, y, epochs=10, batch_size=12, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "keras.Sequential.fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "import keras.models as models\n",
    "\n",
    "if TRAIN_HAS_WHEAT_MODEL:\n",
    "    model_has_wheat.save( os.path.join(model_root, 'build', 'model_has_wheat.h5') )\n",
    "else:\n",
    "    model_has_wheat = models.load_model( os.path.join(model_root, 'build', 'model_has_wheat.h5') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_image_names = pd.DataFrame(['wheat01.jpg'], columns={\"image_name\"})\n",
    "#test_image_names = pd.DataFrame(['2fd875eaa.jpg'], columns={\"image_name\"})\n",
    "\n",
    "test_image_names = pd.DataFrame( os.listdir(os.path.join(data_path, 'test_www')), columns={\"image_name\"})\n",
    "test_images = read_images( os.path.join(data_path, 'test_www'), test_image_names, width=224, height=224 )\n",
    "\n",
    "x_test = vgg16.preprocess_input(test_images)\n",
    "\n",
    "with tf.device('cpu:0'):\n",
    "    x_test_vgg16 = vgg16.preprocess_input(x_test)\n",
    "    x_test_after_vgg = vgg16_model.predict(x_test_vgg16, verbose=True, batch_size=12)\n",
    "    res = model_has_wheat.predict(x_test_after_vgg)\n",
    "    \n",
    "    print(res)\n",
    "    print(test_image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug\n",
    "#config = tf.compat.v1.ConfigProto()\n",
    "#config.gpu_options.allow_growth = True\n",
    "#session = tf.compat.v1.InteractiveSession(config=config)\n",
    "import tensorflow as tf\n",
    "import keras.models as models\n",
    "import keras.applications.vgg16 as vgg16\n",
    "\n",
    "# Load models\n",
    "vgg16_model = vgg16.VGG16(include_top=False, input_shape=(224, 224, 3))\n",
    "model_has_wheat = models.load_model( os.path.join(model_root, 'build', 'model_has_wheat.h5') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_vgg16 = vgg16.preprocess_input(x_test)\n",
    "x_test_after_vgg = vgg16_model.predict(x_test_vgg16, verbose=True, batch_size=12)\n",
    "res = model_has_wheat.predict(x_test_after_vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get variables and their size\n",
    "import sys\n",
    "\n",
    "# These are the usual ipython objects, including this one you are creating\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# Get a sorted list of the objects and their sizes\n",
    "sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augment Data <a class=\"anchor\" id=\"augment_data\"></a>\n",
    "[got to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Model <a class=\"anchor\" id=\"generate_model\"></a>\n",
    "[got to top](#top)\n",
    "\n",
    "You may also start from here, but run  \n",
    "\n",
    "* [Image Helpers](#image_helpers)  \n",
    "* [Data Helpers](#data_helpers)  \n",
    "\n",
    "before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model <a class=\"anchor\" id=\"train_model\"></a>\n",
    "[got to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show Results <a class=\"anchor\" id=\"show_results\"></a>\n",
    "[got to top](#top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = \"1\"\n",
    "array = wheat_helpers.get_array_from_string(\"[1, 2, 3]\")\n",
    "print(array[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggledata_root = \"../../res/data\" # Leave empty for upload on kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read csv and show head of csv\n",
    "data_box = pd.read_csv(kaggledata_root + \"/kaggle/input/global-wheat-detection/train.csv\")\n",
    "data_box.head()\n",
    "\n",
    "wheat_helpers.plot_boundingbox(data_box, kaggledata_root + '/kaggle/input/global-wheat-detection/train/b6ab77fd7.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample image\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "img = mpimg.imread(kaggledata_root + \"/kaggle/input/global-wheat-detection/train/b6ab77fd7.jpg\")\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
